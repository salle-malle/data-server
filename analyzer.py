import json, logging, re, time
from datetime import datetime, date
from bs4 import BeautifulSoup
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
from langchain.prompts import ChatPromptTemplate
from langchain.schema.output_parser import StrOutputParser
import tiktoken

# 1. ê³µí†µ ì„¤ì • -------------------------------------------------------------
load_dotenv()
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# max_tokens ì¦ê°€ë¡œ ë” ìƒì„¸í•œ ìš”ì•½ ìƒì„±
llm = ChatOpenAI(model="gpt-4o-mini", temperature=0, max_tokens=1200)
enc = tiktoken.encoding_for_model("gpt-4o-mini")

# ê°œì„ ëœ í”„ë¡¬í”„íŠ¸ - íˆ¬ìì ê´€ì ê³¼ ìƒì„¸ ë§¥ë½ ì¶”ê°€
prompt = ChatPromptTemplate.from_template("""
ë‹¹ì‹ ì€ SEC 8-K ê³µì‹œë¥¼ ë¶„ì„í•˜ëŠ” **ê¸ˆìœµ ì• ë„ë¦¬ìŠ¤íŠ¸**ì…ë‹ˆë‹¤. 
íˆ¬ììì™€ ë¹„ì¦ˆë‹ˆìŠ¤ ì „ë¬¸ê°€ê°€ ì´í•´í•˜ê¸° ì‰½ë„ë¡ **ë§¥ë½ê³¼ í•¨ì˜ë¥¼ í¬í•¨í•œ ìƒì„¸ ë¶„ì„**ì„ ì œê³µí•˜ì„¸ìš”.

ê³µì‹œì¼: {filing_date}
ë¬¸ì„œ ë‚´ìš©: {full_content}

ë‹¤ìŒ **ì™„ë²½í•˜ê²Œ** JSON í˜•ì‹ìœ¼ë¡œ ì¶œë ¥í•˜ì„¸ìš”:

{{
  "title": "ê³µì‹œ í•µì‹¬ ë‚´ìš©ì„ ë°˜ì˜í•œ êµ¬ì²´ì ì¸ í•œêµ­ì–´ ì œëª© (50ì ì´ë‚´)",
  "narrative": "ê³µì‹œ ë‚´ìš©ì„ ìŠ¤í† ë¦¬í…”ë§ ë°©ì‹ìœ¼ë¡œ ì„¤ëª…í•œ 2-3ê°œ ë‹¨ë½ (ê° ë‹¨ë½ 4-5ë¬¸ì¥, ì—°ê²°ì–´ ì‚¬ìš©ìœ¼ë¡œ íë¦„ ìœ ì§€)",
  "filing_date": "{filing_date}"
}}

ì¤‘ìš” ì§€ì¹¨:
- narrativeëŠ” **ì—°ê²°ì–´ì™€ ë§¥ë½**ì„ ì‚¬ìš©í•´ ìŠ¤í† ë¦¬ì²˜ëŸ¼ ì„œìˆ 
- ë‹¨ìˆœ ë²ˆì—­ì´ ì•„ë‹Œ **ë¹„ì¦ˆë‹ˆìŠ¤ ë§¥ë½ê³¼ í•¨ì˜** í¬í•¨
- ìˆ˜ì¹˜ë‚˜ ë‚ ì§œëŠ” ì •í™•íˆ ì¸ìš©, ì¶”ì¸¡ ê¸ˆì§€
- ëª¨ë“  ë‚´ìš©ì€ ìì—°ìŠ¤ëŸ¬ìš´ í•œêµ­ì–´ë¡œ ì‘ì„±
""")

# 2. í•µì‹¬ í‚¤ì›Œë“œ ì„¸íŠ¸ - í™•ì¥ ë° ê°€ì¤‘ì¹˜ ì¶”ê°€ ------------------------------
CRITICAL_KEYWORDS = {
    "merger_acquisition": {
        "keywords": ["merger", "acquisition", "agreement", "definitive", "purchase", "sale", "disposition", "divestiture"],
        "weight": 1.5
    },
    "executive_changes": {
        "keywords": ["resign", "appointment", "terminate", "ceo", "cfo", "director", "president", "officer", "retire"],
        "weight": 1.3
    },
    "financial_events": {
        "keywords": ["earnings", "revenue", "loss", "dividend", "bankruptcy", "impairment", "writedown", "restructuring"],
        "weight": 1.4
    },
    "material_agreements": {
        "keywords": ["material definitive agreement", "joint venture", "partnership", "contract", "license"],
        "weight": 1.2
    },
    "legal_regulatory": {
        "keywords": ["lawsuit", "settlement", "regulatory", "compliance", "investigation", "sec", "doj"],
        "weight": 1.1
    }
}

# ê°€ì¤‘ì¹˜ê°€ ì ìš©ëœ í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸ ìƒì„±
ALL_KEYWORDS = []
for category, info in CRITICAL_KEYWORDS.items():
    for keyword in info["keywords"]:
        ALL_KEYWORDS.append((keyword.lower(), info["weight"]))

# ê¸¸ì´ ìˆœìœ¼ë¡œ ì •ë ¬ (ê¸´ í‚¤ì›Œë“œê°€ ë¨¼ì € ë§¤ì¹­ë˜ë„ë¡)
ALL_KEYWORDS.sort(key=lambda x: len(x[0]), reverse=True)

# 3. ìœ í‹¸ í•¨ìˆ˜ë“¤ ----------------------------------------------------------
def build_flexible_item_pattern(major: int, minor: int) -> str:
    return (
        rf"(?i)item[\s.\xa0]*{major}[\s.\xa0]*[\.:,]?\s*{minor}"
        r".*?(?=item[\s.\xa0]*\d+[\s.\xa0]*[\.:,]?\s*\d+|signature|$)"
    )

def extract_financial_numbers(text: str) -> list[str]:
    """í…ìŠ¤íŠ¸ì—ì„œ ì¬ë¬´ ê´€ë ¨ ìˆ˜ì¹˜ ì¶”ì¶œ"""
    patterns = [
        r'\$[\d,]+(?:\.\d{2})?(?:\s*(?:million|billion|trillion|ë°±ë§Œ|ì–µ|ì¡°))?',
        r'[\d,]+(?:\.\d{2})?\s*(?:million|billion|trillion|ë°±ë§Œ|ì–µ|ì¡°)\s*(?:ë‹¬ëŸ¬|dollars?)',
        r'[\d,]+(?:\.\d{2})?\s*(?:shares?|ì£¼ì‹|ì£¼)',
        r'[\d,]+(?:\.\d{2})?\s*(?:percent|%)',
    ]
    
    numbers = []
    for pattern in patterns:
        matches = re.findall(pattern, text, re.IGNORECASE)
        numbers.extend(matches)
    
    return list(set(numbers))  # ì¤‘ë³µ ì œê±°

class EnhancedDateExtractor:
    def __init__(self, default_date: str = None):
        """
        Args:
            default_date: ë‚ ì§œ ì¶”ì¶œ ì‹¤íŒ¨ ì‹œ ì‚¬ìš©í•  ê¸°ë³¸ ë‚ ì§œ (YYYY-MM-DD í˜•ì‹)
                         Noneì´ë©´ ì˜¤ëŠ˜ ë‚ ì§œ ì‚¬ìš©
        """
        self.default_date = default_date or date.today().strftime("%Y-%m-%d")
        
        # SEC 8-K íŠ¹í™” ë‚ ì§œ íŒ¨í„´ (ìš°ì„ ìˆœìœ„ ìˆœ)
        self.date_patterns = [
            # 1. SEC í—¤ë” í˜•ì‹
            r"(?i)date\s+of\s+report\s*[:\(]?\s*(\w+\s+\d{1,2},?\s+\d{4})",
            r"(?i)date\s+of\s+earliest\s+event\s+reported\s*[:\(]?\s*(\w+\s+\d{1,2},?\s+\d{4})",
            r"(?i)filing\s+date\s*[:\(]?\s*(\w+\s+\d{1,2},?\s+\d{4})",
            
            # 2. í‘œì¤€ ë‚ ì§œ í˜•ì‹
            r"(\d{4}-\d{2}-\d{2})",                    # 2025-01-15
            r"(\d{1,2}/\d{1,2}/\d{4})",                # 1/15/2025
            r"(\d{1,2}-\d{1,2}-\d{4})",                # 1-15-2025
            
            # 3. ê´„í˜¸ ì•ˆì˜ ë‚ ì§œ
            r"\((\w+\s+\d{1,2},?\s+\d{4})\)",          # (January 15, 2025)
            r"\((\d{1,2}/\d{1,2}/\d{4})\)",            # (1/15/2025)
            r"\((\d{4}-\d{2}-\d{2})\)",                # (2025-01-15)
            
            # 4. ë¬¸ë§¥ìƒ ë‚ ì§œ
            r"(?i)(?:on|dated?|as\s+of|effective)\s+(\w+\s+\d{1,2},?\s+\d{4})",
            r"(?i)(?:on|dated?|as\s+of|effective)\s+(\d{1,2}/\d{1,2}/\d{4})",
            
            # 5. 8-K íŠ¹í™” íŒ¨í„´
            r"(?i)current\s+report\s+.*?(\w+\s+\d{1,2},?\s+\d{4})",
            r"(?i)form\s+8-k\s+.*?(\w+\s+\d{1,2},?\s+\d{4})",
        ]
        
        # ë‚ ì§œ í˜•ì‹ íŒ¨í„´ (íŒŒì‹±ìš©)
        self.date_formats = [
            "%B %d, %Y",     # January 15, 2025
            "%b %d, %Y",     # Jan 15, 2025
            "%B %d %Y",      # January 15 2025
            "%b %d %Y",      # Jan 15 2025
            "%Y-%m-%d",      # 2025-01-15
            "%m/%d/%Y",      # 1/15/2025
            "%m-%d-%Y",      # 1-15-2025
            "%d/%m/%Y",      # 15/1/2025
            "%d-%m-%Y",      # 15-1-2025
        ]
    
    def extract_date_from_html(self, raw_html: str) -> str:
        """HTMLì—ì„œ ë‚ ì§œ ì¶”ì¶œ (ë‹¤ì¤‘ ì „ëµ)"""
        
        # ì „ëµ 1: HTML ë©”íƒ€ë°ì´í„°ì—ì„œ ì¶”ì¶œ
        soup = BeautifulSoup(raw_html, "html.parser")
        
        # SEC-HEADERì—ì„œ ë‚ ì§œ ì°¾ê¸°
        header_date = self._extract_from_sec_header(soup)
        if header_date:
            return header_date
        
        # ì „ëµ 2: í…ìŠ¤íŠ¸ì—ì„œ ì •ê·œì‹ íŒ¨í„´ ë§¤ì¹­
        plain_text = soup.get_text(" ")
        
        # ìƒìœ„ 2000ìì—ì„œ ìš°ì„  ê²€ìƒ‰ (í—¤ë” ë¶€ë¶„)
        header_text = plain_text[:2000]
        date_found = self._extract_with_patterns(header_text)
        if date_found:
            return date_found
        
        # ì „ì²´ í…ìŠ¤íŠ¸ì—ì„œ ê²€ìƒ‰ (í—¤ë”ì—ì„œ ì°¾ì§€ ëª»í•œ ê²½ìš°)
        date_found = self._extract_with_patterns(plain_text)
        if date_found:
            return date_found
        
        # ì „ëµ 3: íŠ¹ì • HTML íƒœê·¸ì—ì„œ ì¶”ì¶œ
        date_found = self._extract_from_html_tags(soup)
        if date_found:
            return date_found
        
        # ì „ëµ 4: ê¸°ë³¸ê°’ ë°˜í™˜
        logger.warning("ë‚ ì§œ ì¶”ì¶œ ì‹¤íŒ¨, ê¸°ë³¸ê°’ ì‚¬ìš©: %s", self.default_date)
        return self.default_date
    
    def _extract_from_sec_header(self, soup: BeautifulSoup) -> str:
        """SEC-HEADERì—ì„œ ë‚ ì§œ ì¶”ì¶œ"""
        # SEC-HEADER ì„¹ì…˜ ì°¾ê¸°
        header_patterns = [
            r"<SEC-HEADER>.*?</SEC-HEADER>",
            r"SEC-HEADER.*?(?=<|$)",
            r"CONFORMED\s+PERIOD\s+OF\s+REPORT[:\s]+(\d{8})",
            r"FILED\s+AS\s+OF\s+DATE[:\s]+(\d{8})",
        ]
        
        text = str(soup)
        for pattern in header_patterns:
            matches = re.findall(pattern, text, re.DOTALL | re.IGNORECASE)
            if matches:
                for match in matches:
                    # 8ìë¦¬ ìˆ«ì ë‚ ì§œ í˜•ì‹ (YYYYMMDD)
                    if isinstance(match, str) and match.isdigit() and len(match) == 8:
                        return self._format_date(match, "%Y%m%d")
                    
                    # ì¼ë°˜ ë‚ ì§œ íŒ¨í„´ ê²€ìƒ‰
                    date_found = self._extract_with_patterns(match)
                    if date_found:
                        return date_found
        
        return None
    
    def _extract_with_patterns(self, text: str) -> str:
        """ì •ê·œì‹ íŒ¨í„´ìœ¼ë¡œ ë‚ ì§œ ì¶”ì¶œ"""
        for pattern in self.date_patterns:
            matches = re.findall(pattern, text, re.IGNORECASE)
            if matches:
                for match in matches:
                    formatted_date = self._format_date(match.strip())
                    if formatted_date:
                        return formatted_date
        return None
    
    def _extract_from_html_tags(self, soup: BeautifulSoup) -> str:
        """HTML íƒœê·¸ì—ì„œ ë‚ ì§œ ì¶”ì¶œ"""
        # ë‚ ì§œ ê´€ë ¨ íƒœê·¸ë“¤ ê²€ìƒ‰
        date_tags = ['time', 'date', 'span', 'div', 'p']
        date_attrs = ['datetime', 'date', 'data-date']
        
        for tag_name in date_tags:
            for tag in soup.find_all(tag_name):
                # ì†ì„±ì—ì„œ ë‚ ì§œ ì°¾ê¸°
                for attr in date_attrs:
                    if tag.get(attr):
                        formatted_date = self._format_date(tag.get(attr))
                        if formatted_date:
                            return formatted_date
                
                # íƒœê·¸ ë‚´ìš©ì—ì„œ ë‚ ì§œ ì°¾ê¸°
                if tag.string:
                    formatted_date = self._format_date(tag.string.strip())
                    if formatted_date:
                        return formatted_date
        
        return None
    
    def _format_date(self, date_str: str, known_format: str = None) -> str:
        """ë‚ ì§œ ë¬¸ìì—´ì„ YYYY-MM-DD í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
        if not date_str:
            return None
        
        date_str = date_str.strip()
        
        # ì•Œë ¤ì§„ í˜•ì‹ì´ ìˆìœ¼ë©´ ì§ì ‘ íŒŒì‹±
        if known_format:
            try:
                return datetime.strptime(date_str, known_format).strftime("%Y-%m-%d")
            except ValueError:
                pass
        
        # 8ìë¦¬ ìˆ«ì (YYYYMMDD) ì²˜ë¦¬
        if date_str.isdigit() and len(date_str) == 8:
            try:
                return f"{date_str[:4]}-{date_str[4:6]}-{date_str[6:8]}"
            except:
                pass
        
        # ë‹¤ì–‘í•œ í˜•ì‹ìœ¼ë¡œ ì‹œë„
        for fmt in self.date_formats:
            try:
                parsed_date = datetime.strptime(date_str, fmt)
                # ë¯¸ë˜ ë‚ ì§œ ì²´í¬ (ë„ˆë¬´ ë¯¸ë˜ë©´ ì œì™¸)
                if parsed_date.year > datetime.now().year + 5:
                    continue
                # ë„ˆë¬´ ê³¼ê±° ë‚ ì§œ ì²´í¬ (1990ë…„ ì´ì „ì´ë©´ ì œì™¸)
                if parsed_date.year < 1990:
                    continue
                return parsed_date.strftime("%Y-%m-%d")
            except ValueError:
                continue
        
        return None

# 5. ê°œì„ ëœ Smart8KExtractor -----------------------------------------------
class Smart8KExtractor:
    def __init__(self, default_date: str = None):
        """
        Args:
            default_date: ë‚ ì§œ ì¶”ì¶œ ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ê°’ (YYYY-MM-DD)
        """
        self.date_extractor = EnhancedDateExtractor(default_date)
        
        self.item_patterns = {
            "ITEM_1_01": {
                "pattern": build_flexible_item_pattern(1, 1),
                "importance": 8,
                "korean_name": "ì¤‘ìš” ê³„ì•½ ì²´ê²°",
                "keywords": ["agreement", "contract", "definitive", "material"]
            },
            "ITEM_1_02": {
                "pattern": build_flexible_item_pattern(1, 2),
                "importance": 7,
                "korean_name": "ê³„ì•½ ì¢…ë£Œ",
                "keywords": ["termination", "terminate", "end", "expire"]
            },
            "ITEM_2_01": {
                "pattern": build_flexible_item_pattern(2, 1),
                "importance": 9,
                "korean_name": "ìì‚° ì¸ìˆ˜/ë§¤ê°",
                "keywords": ["acquisition", "merger", "purchase", "sale", "dispose", "acquire"]
            },
            "ITEM_2_02": {
                "pattern": build_flexible_item_pattern(2, 2),
                "importance": 8,
                "korean_name": "ì‹¤ì  ë°œí‘œ",
                "keywords": ["earnings", "revenue", "results", "financial", "quarter", "fiscal"]
            },
            "ITEM_3_02": {
                "pattern": build_flexible_item_pattern(3, 2),
                "importance": 6,
                "korean_name": "ì£¼ì‹ ë§¤ê°",
                "keywords": ["sale", "equity", "stock", "shares"]
            },
            "ITEM_4_01": {
                "pattern": build_flexible_item_pattern(4, 1),
                "importance": 6,
                "korean_name": "ê°ì‚¬ì¸ ë³€ê²½",
                "keywords": ["auditor", "accountant", "change"]
            },
            "ITEM_5_02": {
                "pattern": build_flexible_item_pattern(5, 2),
                "importance": 9,
                "korean_name": "ì„ì› ë³€ê²½",
                "keywords": ["appoint", "resign", "retire", "ceo", "cfo", "president", "officer", "director"]
            },
            "ITEM_7_01": {
                "pattern": build_flexible_item_pattern(7, 1),
                "importance": 7,
                "korean_name": "ê·œì œ ì ˆì°¨",
                "keywords": ["regulatory", "proceeding", "investigation"]
            },
            "ITEM_8_01": {
                "pattern": build_flexible_item_pattern(8, 1),
                "importance": 5,
                "korean_name": "ê¸°íƒ€ ì¤‘ìš” ì‚¬ê±´",
                "keywords": ["other", "event", "material"]
            },
            "ITEM_9_01": {
                "pattern": build_flexible_item_pattern(9, 1),
                "importance": 4,
                "korean_name": "ì¬ë¬´ì œí‘œ ë° ì „ì‹œë¬¼",
                "keywords": ["financial", "statements", "exhibits"]
            }
        }

    def smart_filter(self, raw_html: str) -> dict:
        soup = BeautifulSoup(raw_html, "html.parser")
        
        # ë¶ˆí•„ìš”í•œ íƒœê·¸ ì œê±°
        for tag in soup.find_all(["header", "footer", "nav", "script", "style"]):
            tag.decompose()
        
        full_text = soup.get_text(separator=" ")
        
        # í…Œì´ë¸” ì •ë³´ - ë” í¬ê´„ì ìœ¼ë¡œ ìˆ˜ì§‘
        tables = []
        for tbl in soup.find_all("table"):
            txt = tbl.get_text(" ", strip=True)
            # ë” ë§ì€ ì¤‘ìš” í‚¤ì›Œë“œ í¬í•¨
            if any(kw in txt.lower() for kw in [
                "merger", "agreement", "officer", "director", "shares", "vote", 
                "financial", "revenue", "earnings", "dividend", "debt"
            ]):
                tables.append(txt)
        
        # ê°•ì¡°ëœ í…ìŠ¤íŠ¸ ìˆ˜ì§‘
        emphasizes = []
        for em in soup.find_all(["b", "strong", "em", "u"]):
            txt = em.get_text(" ", strip=True)
            if len(txt) > 10:  # ë„ˆë¬´ ì§§ì€ í…ìŠ¤íŠ¸ ì œì™¸
                emphasizes.append(txt)
        
        return {
            "full_text": full_text,
            "tables": tables[:3],  # 3ê°œë¡œ ì¦ê°€
            "emphasized": emphasizes[:15]  # 15ê°œë¡œ ì¦ê°€
        }

    def extract_filing_date(self, raw_html: str) -> str:
        """ê°•í™”ëœ ë‚ ì§œ ì¶”ì¶œ"""
        return self.date_extractor.extract_date_from_html(raw_html)

    def extract_important_content(self, text: str) -> str:
        """ë” í’ë¶€í•œ ë§¥ë½ ì •ë³´ë¥¼ ì¶”ì¶œ"""
        important_parts = []
        
        # 1) Item íŒ¨í„´ ë§¤ì¹­ - ë” ê¸´ ë¸”ë¡ í—ˆìš©
        for code, cfg in sorted(
            self.item_patterns.items(),
            key=lambda x: x[1]["importance"],
            reverse=True
        ):
            matches = re.findall(cfg["pattern"], text, re.DOTALL)
            if matches:
                block = matches[0].strip()
                if len(block) > 80:  # ìµœì†Œ ê¸¸ì´ 80ìë¡œ ì¦ê°€
                    # ë¸”ë¡ í¬ê¸°ë¥¼ 1500ìë¡œ ì¦ê°€
                    important_parts.append(f"[{cfg['korean_name']}]\n{block[:1500]}")
        
        # 2) í‚¤ì›Œë“œ ê¸°ë°˜ ì¤‘ìš” ë¬¸ì¥ - ê°€ì¤‘ì¹˜ ì ìš©
        sentences = re.split(r"[.!?]+", text)
        weighted_sentences = []
        
        for sent in sentences:
            sent = sent.strip()
            if len(sent) < 40:  # ìµœì†Œ ê¸¸ì´ 40ìë¡œ ê°ì†Œ
                continue
            
            # ê°€ì¤‘ì¹˜ ê³„ì‚°
            total_weight = 0
            for keyword, weight in ALL_KEYWORDS:
                if keyword in sent.lower():
                    total_weight += weight
            
            if total_weight >= 1.5:  # ê°€ì¤‘ì¹˜ ê¸°ì¤€ìœ¼ë¡œ í•„í„°ë§
                weighted_sentences.append((sent, total_weight))
        
        # ê°€ì¤‘ì¹˜ ìˆœìœ¼ë¡œ ì •ë ¬í•˜ì—¬ ìƒìœ„ ë¬¸ì¥ ì„ íƒ
        weighted_sentences.sort(key=lambda x: x[1], reverse=True)
        for sent, weight in weighted_sentences[:12]:  # 12ê°œë¡œ ì¦ê°€
            important_parts.append(sent)
        
        # 3) ìˆ˜ì¹˜ ì •ë³´ ì¶”ê°€
        financial_numbers = extract_financial_numbers(text)
        if financial_numbers:
            numbers_text = "ì£¼ìš” ìˆ˜ì¹˜: " + ", ".join(financial_numbers[:10])
            important_parts.append(numbers_text)
        
        # 4) í†µí•© ë° í† í° ì œí•œ
        combined = "\n\n".join(important_parts[:15])  # 15ê°œ ì„¹ì…˜ìœ¼ë¡œ ì¦ê°€
        
        # í† í° ìˆ˜ ì œí•œì„ 4500ìœ¼ë¡œ ì¦ê°€
        if len(enc.encode(combined)) > 4500:
            combined = combined[:12000]  # ë¬¸ì ìˆ˜ ì œí•œë„ ì¦ê°€
        
        return combined

# 6. ê°„ì†Œí™” í•¨ìˆ˜ ----------------------------------------------------------
def simplify_8k_results(results):
    """
    analyze_8k í•¨ìˆ˜ì˜ ê²°ê³¼ì—ì„œ title, narrative, filing_dateë§Œ ì¶”ì¶œ
    """
    simplified = []
    
    for result in results:
        simplified_item = {
            "title": result.get("title", "ì œëª© ì—†ìŒ"),
            "narrative": result.get("narrative", "ë‚´ìš© ì—†ìŒ"),
            "filing_date": result.get("filing_date", "ë‚ ì§œ ì •ë³´ ì—†ìŒ")
        }
        simplified.append(simplified_item)
    
    return simplified

# 7. ğŸ“Œ ê°•í™”ëœ ë¶„ì„ í•¨ìˆ˜ (ë‚ ì§œ ë³´ì¥) ----------------------------------------
def analyze_8k(docs: list[str], max_cost: float = 8.0, default_date: str = None) -> list[dict]:
    """
    SEC 8-K ë¬¸ì„œ ë¶„ì„ (ë‚ ì§œ ì¶”ì¶œ ê°•í™”)
    
    Args:
        docs: ë¶„ì„í•  ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸
        max_cost: ìµœëŒ€ ë¹„ìš© í•œë„
        default_date: ë‚ ì§œ ì¶”ì¶œ ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ê°’ (YYYY-MM-DD)
    
    Returns:
        ê°„ì†Œí™”ëœ ë¶„ì„ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
    """
    if not docs:
        return []

    # ê¸°ë³¸ê°’ ì„¤ì • (ì˜¤ëŠ˜ ë‚ ì§œ)
    if default_date is None:
        default_date = date.today().strftime("%Y-%m-%d")

    extractor = Smart8KExtractor(default_date)
    results, total_cost = [], 0.0

    for idx, raw in enumerate(docs):
        logger.info("ë¬¸ì„œ %s ë¶„ì„ ì¤‘ (ê°œì„ ëœ ë²„ì „)...", idx + 1)
        
        # í† í° ë¹„ìš© ì¬ê³„ì‚° (ë” ë§ì€ í† í° ì‚¬ìš©)
        est_tokens = len(enc.encode(raw[:15_000])) * 0.4  # ì¶”ì • ë¹„ìœ¨ ì¦ê°€
        est_dollars = est_tokens / 1_000 * 0.00075
        if total_cost + est_dollars > max_cost:
            logger.warning("ì˜ˆì‚° ì´ˆê³¼ ì˜ˆìƒ, ë¬¸ì„œ %s ìŠ¤í‚µ", idx + 1)
            continue

        # ğŸ“Œ ê°•í™”ëœ ë‚ ì§œ ì¶”ì¶œ
        filing_date = extractor.extract_filing_date(raw)
        logger.info("ì¶”ì¶œëœ ë‚ ì§œ: %s", filing_date)
        
        # ë‚ ì§œ í˜•ì‹ ê²€ì¦ (YYYY-MM-DD)
        if not re.match(r'^\d{4}-\d{2}-\d{2}$', filing_date):
            logger.warning("ë‚ ì§œ í˜•ì‹ ë¶ˆì¼ì¹˜, ê¸°ë³¸ê°’ ì‚¬ìš©: %s", default_date)
            filing_date = default_date
        
        filtered = extractor.smart_filter(raw)
        
        # ë” í’ë¶€í•œ ì»¨í…ìŠ¤íŠ¸ ì¶”ì¶œ
        important_content = extractor.extract_important_content(filtered["full_text"])
        
        # í…Œì´ë¸” ì •ë³´ ì¶”ê°€ (ë” ë§ì€ ì •ë³´)
        if filtered["tables"]:
            table_content = "\n".join(filtered["tables"])
            important_content += f"\n\n[í…Œì´ë¸” ì •ë³´]\n{table_content[:1500]}"  # 1500ìë¡œ ì¦ê°€
        
        # ê°•ì¡°ëœ í…ìŠ¤íŠ¸ ì¶”ê°€
        if filtered["emphasized"]:
            emphasized_content = "\n".join(filtered["emphasized"][:10])
            important_content += f"\n\n[ê°•ì¡°ëœ ë‚´ìš©]\n{emphasized_content}"

        # API í˜¸ì¶œ ì „ ë”œë ˆì´
        if idx > 0:
            logger.info("API Rate Limit ë°©ì§€ë¥¼ ìœ„í•´ 3ì´ˆ ëŒ€ê¸°...")
            time.sleep(3)  # 3ì´ˆë¡œ ì¦ê°€

        # 429 ì˜¤ë¥˜ ì¬ì‹œë„ ë¡œì§
        max_retries = 5
        retry_delay = 2  # ì´ˆê¸° ë”œë ˆì´ 2ì´ˆë¡œ ì¦ê°€
        
        for attempt in range(max_retries):
            try:
                response = (prompt | llm | StrOutputParser()).invoke({
                    "filing_date": filing_date,
                    "full_content": important_content
                })
                break
                
            except Exception as e:
                error_msg = str(e)
                if "429" in error_msg or "rate" in error_msg.lower():
                    logger.warning(
                        "429 ì˜¤ë¥˜ ë°œìƒ. %sì´ˆ í›„ ì¬ì‹œë„ (%d/%d)",
                        retry_delay, attempt + 1, max_retries
                    )
                    time.sleep(retry_delay)
                    retry_delay *= 2
                    if attempt == max_retries - 1:
                        logger.error("ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜ ì´ˆê³¼. ë¬¸ì„œ %s ìŠ¤í‚µ", idx + 1)
                        response = None
                else:
                    logger.error("API í˜¸ì¶œ ì‹¤íŒ¨: %s", e)
                    response = None
                    break

        if response is None:
            continue

        try:
            record = json.loads(response)
            record_date = record.get("filing_date", filing_date)
            if not re.match(r'^\d{4}-\d{2}-\d{2}$', record_date):
                record["filing_date"] = filing_date
                logger.info("ì‘ë‹µ ë‚ ì§œ í˜•ì‹ ë³´ì •: %s", filing_date)
            
            record.update({
                "document_index": idx + 1,
                "processed_at": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                "analysis_version": "v4_enhanced_date",  # ë²„ì „ ì •ë³´ ì¶”ê°€
                "content_length": len(important_content)
            })
            
            # ë¹„ìš© ê³„ì‚°
            token_in = len(enc.encode(important_content))
            token_out = len(enc.encode(response))
            cost = token_in * 0.00015 / 1_000 + token_out * 0.00060 / 1_000
            total_cost += cost
            
            results.append(record)
            logger.info("ë¬¸ì„œ %s ë¶„ì„ ì™„ë£Œ (ë¹„ìš© +$%.4f, í† í°: %d)", idx + 1, cost, token_in)
            
        except json.JSONDecodeError as e:
            logger.error("JSON íŒŒì‹± ì‹¤íŒ¨ - ë¬¸ì„œ %s: %s", idx + 1, e)
            continue

        if total_cost >= max_cost:
            logger.info("ì˜ˆì‚° ì†Œì§„, ì¶”ê°€ ë¬¸ì„œ ì¤‘ë‹¨")
            break

    logger.info("ë¶„ì„ ì™„ë£Œ: %sê±´, ì´ ë¹„ìš© $%.4f", len(results), total_cost)

    # ğŸ“Œ ê°œì„ ëœ ë¹ˆ ê²°ê³¼ ì²˜ë¦¬ (ë‚ ì§œ ë³´ì¥)
    if not results:
        return [{
            "title": "ë¶„ì„ ê°€ëŠ¥í•œ ì¤‘ìš” ê³µì‹œ ë‚´ìš© ì—†ìŒ",
            "narrative": "ì œê³µëœ ë¬¸ì„œì—ì„œ íˆ¬ììë‚˜ ë¹„ì¦ˆë‹ˆìŠ¤ ê´€ì ì—ì„œ ì¤‘ìš”í•œ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ì—ˆìŠµë‹ˆë‹¤. ë¬¸ì„œ í˜•ì‹ì´ë‚˜ ë‚´ìš©ì— ë¬¸ì œê°€ ìˆê±°ë‚˜, ì¤‘ìš”ë„ê°€ ë‚®ì€ ê¸°ìˆ ì  ê³µì‹œì¼ ê°€ëŠ¥ì„±ì´ ìˆìŠµë‹ˆë‹¤.",
            "filing_date": default_date
        }]

    return simplify_8k_results(results)

# 8. ì‚¬ìš© ì˜ˆì‹œ -------------------------------------------------------------
if __name__ == "__main__":
    # ì˜ˆì‹œ ì‚¬ìš©ë²•
    docs = ["ë¬¸ì„œ1 ë‚´ìš©", "ë¬¸ì„œ2 ë‚´ìš©", "ë¬¸ì„œ3 ë‚´ìš©"]
    default_date = "None"
    results = analyze_8k(docs, default_date=default_date)
    
    # ê²°ê³¼ ì¶œë ¥
    for result in results:
        print(f"ì œëª©: {result['title']}")
        print(f"ë‚´ìš©: {result['narrative']}")
        print(f"ë‚ ì§œ: {result['filing_date']}")  # ë¬´ì¡°ê±´ YYYY-MM-DD í˜•ì‹
        print("-" * 50)